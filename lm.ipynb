{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrobNodOHQ5xgIDsQKit42",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aokinb/LIN_205A_Project/blob/main/lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://colab.research.google.com/drive/1dr7hXhrHh5HBN30lXZLgXxXuEDxyYpii?usp=sharing#scrollTo=ptpp-0m2nsQZ\n",
        "\n",
        "Make sure to activate GPU (Edit > Notebook settings)"
      ],
      "metadata": {
        "id": "VKTp8oezY-63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbvQhxoXTAxT",
        "outputId": "06602f4c-17a3-43f9-d89d-78cc2583aea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun  6 21:23:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run to upload zipped folder & unzip into colab:"
      ],
      "metadata": {
        "id": "u6cpRsVnWxoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"Uploading_Data_Colab_1.xlsx\" with length 9000 bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "IXsfVy_eTLwb",
        "outputId": "264c0b02-2d5d-4c2c-c231-33b2d928bfed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28ebf918-234b-4f37-86e0-ca17bcc6ec21\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28ebf918-234b-4f37-86e0-ca17bcc6ec21\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving merged_revised.zip to merged_revised.zip\n",
            "User uploaded file \"Uploading_Data_Colab_1.xlsx\" with length 9000 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip merged_revised.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTcWtYC6TMPZ",
        "outputId": "9c7bc12d-ed77-42ee-fab8-9d36e2ed2d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  merged_revised.zip\n",
            "   creating: merged_revised/\n",
            "  inflating: merged_revised/all.txt  \n",
            "  inflating: __MACOSX/merged_revised/._all.txt  \n",
            "  inflating: merged_revised/.DS_Store  \n",
            "  inflating: __MACOSX/merged_revised/._.DS_Store  \n",
            "   creating: merged_revised/democrat_by_decade_revised/\n",
            "   creating: merged_revised/republican_by_decade_revised/\n",
            "   creating: merged_revised/democrat_by_year_revised/\n",
            "   creating: merged_revised/republican_by_year_revised/\n",
            "   creating: merged_revised/by_speaker/\n",
            "  inflating: merged_revised/democrat_by_decade_revised/.DS_Store  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_decade_revised/._.DS_Store  \n",
            "  inflating: merged_revised/democrat_by_decade_revised/1980-1988_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_decade_revised/._1980-1988_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_decade_revised/1960-1976_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_decade_revised/._1960-1976_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_decade_revised/2012-2020_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_decade_revised/._2012-2020_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_decade_revised/2000-2008_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_decade_revised/._2000-2008_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_decade_revised/1992-1996_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_decade_revised/._1992-1996_Democrat.txt  \n",
            "  inflating: merged_revised/republican_by_decade_revised/1992-1996_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_decade_revised/._1992-1996_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_decade_revised/1980-1988_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_decade_revised/._1980-1988_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_decade_revised/.DS_Store  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_decade_revised/._.DS_Store  \n",
            "  inflating: merged_revised/republican_by_decade_revised/2012-2020_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_decade_revised/._2012-2020_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_decade_revised/1960-1976_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_decade_revised/._1960-1976_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_decade_revised/2000-2008_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_decade_revised/._2000-2008_Republican.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/1980_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._1980_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/1992_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._1992_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/.DS_Store  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._.DS_Store  \n",
            "  inflating: merged_revised/democrat_by_year_revised/2012_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._2012_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/2000_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._2000_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/1960_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._1960_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/1988_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._1988_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/2008_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._2008_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/1976_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._1976_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/1996_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._1996_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/1984_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._1984_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/2020_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._2020_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/2004_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._2004_Democrat.txt  \n",
            "  inflating: merged_revised/democrat_by_year_revised/2016_Democrat.txt  \n",
            "  inflating: __MACOSX/merged_revised/democrat_by_year_revised/._2016_Democrat.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/2008_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._2008_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/.DS_Store  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._.DS_Store  \n",
            "  inflating: merged_revised/republican_by_year_revised/2000_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._2000_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/2012_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._2012_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/2016_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._2016_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/2004_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._2004_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/1960_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._1960_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/1996_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._1996_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/1984_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._1984_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/1976_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._1976_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/1980_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._1980_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/2020_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._2020_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/1988_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._1988_Republican.txt  \n",
            "  inflating: merged_revised/republican_by_year_revised/1992_Republican.txt  \n",
            "  inflating: __MACOSX/merged_revised/republican_by_year_revised/._1992_Republican.txt  \n",
            "  inflating: merged_revised/by_speaker/Nixon_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Nixon_all.txt  \n",
            "  inflating: merged_revised/by_speaker/Carter_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Carter_all.txt  \n",
            "  inflating: merged_revised/by_speaker/.DS_Store  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._.DS_Store  \n",
            "  inflating: merged_revised/by_speaker/Obama_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Obama_all.txt  \n",
            "  inflating: merged_revised/by_speaker/Biden_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Biden_all.txt  \n",
            "  inflating: merged_revised/by_speaker/Gore_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Gore_all.txt  \n",
            "  inflating: merged_revised/by_speaker/WBush_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._WBush_all.txt  \n",
            "  inflating: merged_revised/by_speaker/Kennedy_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Kennedy_all.txt  \n",
            "  inflating: merged_revised/by_speaker/Trump_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Trump_all.txt  \n",
            "  inflating: merged_revised/by_speaker/Clinton_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Clinton_all.txt  \n",
            "  inflating: merged_revised/by_speaker/Reagan_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._Reagan_all.txt  \n",
            "  inflating: merged_revised/by_speaker/HWBush_all.txt  \n",
            "  inflating: __MACOSX/merged_revised/by_speaker/._HWBush_all.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace path name with file we're using + rerun"
      ],
      "metadata": {
        "id": "C2oDjleTWt4R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo7NmdfAS8SU",
        "outputId": "4becb6c9-a207-4ccf-9f0d-d746e16632fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    13  39445 219534 /content/merged_revised/by_speaker/WBush_all.txt\n"
          ]
        }
      ],
      "source": [
        "!wc /content/merged_revised/by_speaker/WBush_all.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the head/tail values based on word count for each file"
      ],
      "metadata": {
        "id": "YGVOLi6_WoeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -200000 /content/merged_revised/by_speaker/WBush_all.txt > train.txt"
      ],
      "metadata": {
        "id": "ulWJUFyCS-Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -19534 /content/merged_revised/by_speaker/WBush_all.txt > dev.txt"
      ],
      "metadata": {
        "id": "KaYs8u5MU5iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/27c1b656cca75efa0cc414d3bf4e6aacf24829de/examples/run_lm_finetuning.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN5m2U-uVHYp",
        "outputId": "d95189d8-48fd-49a5-fd5a-7f87dc97e1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-06 21:27:39--  https://raw.githubusercontent.com/huggingface/transformers/27c1b656cca75efa0cc414d3bf4e6aacf24829de/examples/run_lm_finetuning.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31078 (30K) [text/plain]\n",
            "Saving to: ‘run_lm_finetuning.py’\n",
            "\n",
            "\rrun_lm_finetuning.p   0%[                    ]       0  --.-KB/s               \rrun_lm_finetuning.p 100%[===================>]  30.35K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-06-06 21:27:39 (82.1 MB/s) - ‘run_lm_finetuning.py’ saved [31078/31078]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrK674gdVMkK",
        "outputId": "ff7a2179-fccf-4387-e7d1-81aa9491ef00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 29.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then rerun this again:"
      ],
      "metadata": {
        "id": "EYkwBnSQW_is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_lm_finetuning.py \\\n",
        "    --output_dir=output \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=gpt2 \\\n",
        "    --do_train \\\n",
        "    --per_gpu_train_batch_size=1 \\\n",
        "    --save_steps=-1 \\\n",
        "    --num_train_epochs=2 \\\n",
        "    --train_data_file=train.txt \\\n",
        "    --do_eval \\\n",
        "    --eval_data_file=dev.txt \\\n",
        "    --overwrite_output_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmemhTSLVPr5",
        "outputId": "eaffb361-116b-4f56-cf37-e6792f565eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06/06/2022 21:28:05 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "\rDownloading:   0% 0.00/665 [00:00<?, ?B/s]\rDownloading: 100% 665/665 [00:00<00:00, 927kB/s]\n",
            "Downloading: 100% 0.99M/0.99M [00:00<00:00, 48.8MB/s]\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 33.9MB/s]\n",
            "Downloading: 100% 523M/523M [00:11<00:00, 49.6MB/s]\n",
            "06/06/2022 21:28:33 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir='', config_name='', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=True, eval_all_checkpoints=False, eval_data_file='dev.txt', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=1, save_steps=-1, save_total_limit=None, seed=42, server_ip='', server_port='', tokenizer_name='', train_data_file='train.txt', warmup_steps=0, weight_decay=0.0)\n",
            "06/06/2022 21:28:33 - INFO - __main__ -   Creating features from dataset file at \n",
            "06/06/2022 21:28:33 - INFO - __main__ -   Saving features into cached file gpt2_cached_lm_1024_train.txt\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "06/06/2022 21:28:33 - INFO - __main__ -   ***** Running training *****\n",
            "06/06/2022 21:28:33 - INFO - __main__ -     Num examples = 49\n",
            "06/06/2022 21:28:33 - INFO - __main__ -     Num Epochs = 2\n",
            "06/06/2022 21:28:33 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
            "06/06/2022 21:28:33 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "06/06/2022 21:28:33 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "06/06/2022 21:28:33 - INFO - __main__ -     Total optimization steps = 98\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/49 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/49 [00:00<00:29,  1.65it/s]\u001b[A\n",
            "Iteration:   4% 2/49 [00:00<00:21,  2.22it/s]\u001b[A\n",
            "Iteration:   6% 3/49 [00:01<00:18,  2.46it/s]\u001b[A\n",
            "Iteration:   8% 4/49 [00:01<00:17,  2.58it/s]\u001b[A\n",
            "Iteration:  10% 5/49 [00:02<00:16,  2.66it/s]\u001b[A\n",
            "Iteration:  12% 6/49 [00:02<00:15,  2.72it/s]\u001b[A\n",
            "Iteration:  14% 7/49 [00:02<00:15,  2.75it/s]\u001b[A\n",
            "Iteration:  16% 8/49 [00:03<00:14,  2.76it/s]\u001b[A\n",
            "Iteration:  18% 9/49 [00:03<00:14,  2.77it/s]\u001b[A\n",
            "Iteration:  20% 10/49 [00:03<00:13,  2.79it/s]\u001b[A\n",
            "Iteration:  22% 11/49 [00:04<00:13,  2.79it/s]\u001b[A\n",
            "Iteration:  24% 12/49 [00:04<00:13,  2.80it/s]\u001b[A\n",
            "Iteration:  27% 13/49 [00:04<00:12,  2.80it/s]\u001b[A\n",
            "Iteration:  29% 14/49 [00:05<00:12,  2.80it/s]\u001b[A\n",
            "Iteration:  31% 15/49 [00:05<00:12,  2.80it/s]\u001b[A\n",
            "Iteration:  33% 16/49 [00:05<00:11,  2.81it/s]\u001b[A\n",
            "Iteration:  35% 17/49 [00:06<00:11,  2.81it/s]\u001b[A\n",
            "Iteration:  37% 18/49 [00:06<00:11,  2.81it/s]\u001b[A\n",
            "Iteration:  39% 19/49 [00:07<00:10,  2.80it/s]\u001b[A\n",
            "Iteration:  41% 20/49 [00:07<00:10,  2.80it/s]\u001b[A\n",
            "Iteration:  43% 21/49 [00:07<00:09,  2.81it/s]\u001b[A\n",
            "Iteration:  45% 22/49 [00:08<00:09,  2.81it/s]\u001b[A\n",
            "Iteration:  47% 23/49 [00:08<00:09,  2.80it/s]\u001b[A\n",
            "Iteration:  49% 24/49 [00:08<00:08,  2.80it/s]\u001b[A\n",
            "Iteration:  51% 25/49 [00:09<00:08,  2.80it/s]\u001b[A\n",
            "Iteration:  53% 26/49 [00:09<00:08,  2.80it/s]\u001b[A\n",
            "Iteration:  55% 27/49 [00:09<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  57% 28/49 [00:10<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  59% 29/49 [00:10<00:07,  2.80it/s]\u001b[A\n",
            "Iteration:  61% 30/49 [00:10<00:06,  2.80it/s]\u001b[A\n",
            "Iteration:  63% 31/49 [00:11<00:06,  2.80it/s]\u001b[A\n",
            "Iteration:  65% 32/49 [00:11<00:06,  2.80it/s]\u001b[A\n",
            "Iteration:  67% 33/49 [00:12<00:05,  2.79it/s]\u001b[A\n",
            "Iteration:  69% 34/49 [00:12<00:05,  2.79it/s]\u001b[A\n",
            "Iteration:  71% 35/49 [00:12<00:05,  2.79it/s]\u001b[A\n",
            "Iteration:  73% 36/49 [00:13<00:04,  2.79it/s]\u001b[A\n",
            "Iteration:  76% 37/49 [00:13<00:04,  2.79it/s]\u001b[A\n",
            "Iteration:  78% 38/49 [00:13<00:03,  2.79it/s]\u001b[A\n",
            "Iteration:  80% 39/49 [00:14<00:03,  2.79it/s]\u001b[A\n",
            "Iteration:  82% 40/49 [00:14<00:03,  2.79it/s]\u001b[A\n",
            "Iteration:  84% 41/49 [00:14<00:02,  2.80it/s]\u001b[A\n",
            "Iteration:  86% 42/49 [00:15<00:02,  2.80it/s]\u001b[A\n",
            "Iteration:  88% 43/49 [00:15<00:02,  2.80it/s]\u001b[A\n",
            "Iteration:  90% 44/49 [00:15<00:01,  2.79it/s]\u001b[A\n",
            "Iteration:  92% 45/49 [00:16<00:01,  2.79it/s]\u001b[A\n",
            "Iteration:  94% 46/49 [00:16<00:01,  2.79it/s]\u001b[A\n",
            "Iteration:  96% 47/49 [00:17<00:00,  2.78it/s]\u001b[A\n",
            "Iteration:  98% 48/49 [00:17<00:00,  2.78it/s]\u001b[A\n",
            "Iteration: 100% 49/49 [00:17<00:00,  2.76it/s]\n",
            "Epoch:  50% 1/2 [00:17<00:17, 17.74s/it]\n",
            "Iteration:   0% 0/49 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "\n",
            "Iteration:   2% 1/49 [00:00<00:17,  2.75it/s]\u001b[A\n",
            "Iteration:   4% 2/49 [00:00<00:16,  2.77it/s]\u001b[A\n",
            "Iteration:   6% 3/49 [00:01<00:16,  2.76it/s]\u001b[A\n",
            "Iteration:   8% 4/49 [00:01<00:16,  2.76it/s]\u001b[A\n",
            "Iteration:  10% 5/49 [00:01<00:15,  2.77it/s]\u001b[A\n",
            "Iteration:  12% 6/49 [00:02<00:15,  2.77it/s]\u001b[A\n",
            "Iteration:  14% 7/49 [00:02<00:15,  2.77it/s]\u001b[A\n",
            "Iteration:  16% 8/49 [00:02<00:14,  2.77it/s]\u001b[A\n",
            "Iteration:  18% 9/49 [00:03<00:14,  2.76it/s]\u001b[A\n",
            "Iteration:  20% 10/49 [00:03<00:14,  2.77it/s]\u001b[A\n",
            "Iteration:  22% 11/49 [00:03<00:13,  2.77it/s]\u001b[A\n",
            "Iteration:  24% 12/49 [00:04<00:13,  2.76it/s]\u001b[A\n",
            "Iteration:  27% 13/49 [00:04<00:13,  2.77it/s]\u001b[A\n",
            "Iteration:  29% 14/49 [00:05<00:12,  2.76it/s]\u001b[A\n",
            "Iteration:  31% 15/49 [00:05<00:12,  2.76it/s]\u001b[A\n",
            "Iteration:  33% 16/49 [00:05<00:11,  2.76it/s]\u001b[A\n",
            "Iteration:  35% 17/49 [00:06<00:11,  2.75it/s]\u001b[A\n",
            "Iteration:  37% 18/49 [00:06<00:11,  2.75it/s]\u001b[A\n",
            "Iteration:  39% 19/49 [00:06<00:10,  2.76it/s]\u001b[A\n",
            "Iteration:  41% 20/49 [00:07<00:10,  2.75it/s]\u001b[A\n",
            "Iteration:  43% 21/49 [00:07<00:10,  2.75it/s]\u001b[A\n",
            "Iteration:  45% 22/49 [00:07<00:09,  2.75it/s]\u001b[A\n",
            "Iteration:  47% 23/49 [00:08<00:09,  2.75it/s]\u001b[A\n",
            "Iteration:  49% 24/49 [00:08<00:09,  2.75it/s]\u001b[A\n",
            "Iteration:  51% 25/49 [00:09<00:08,  2.75it/s]\u001b[A\n",
            "Iteration:  53% 26/49 [00:09<00:08,  2.73it/s]\u001b[A\n",
            "Iteration:  55% 27/49 [00:09<00:08,  2.74it/s]\u001b[A\n",
            "Iteration:  57% 28/49 [00:10<00:07,  2.75it/s]\u001b[A\n",
            "Iteration:  59% 29/49 [00:10<00:07,  2.74it/s]\u001b[A\n",
            "Iteration:  61% 30/49 [00:10<00:06,  2.75it/s]\u001b[A\n",
            "Iteration:  63% 31/49 [00:11<00:06,  2.75it/s]\u001b[A\n",
            "Iteration:  65% 32/49 [00:11<00:06,  2.74it/s]\u001b[A\n",
            "Iteration:  67% 33/49 [00:11<00:05,  2.74it/s]\u001b[A\n",
            "Iteration:  69% 34/49 [00:12<00:05,  2.74it/s]\u001b[A\n",
            "Iteration:  71% 35/49 [00:12<00:05,  2.74it/s]\u001b[A\n",
            "Iteration:  73% 36/49 [00:13<00:04,  2.74it/s]\u001b[A\n",
            "Iteration:  76% 37/49 [00:13<00:04,  2.74it/s]\u001b[A\n",
            "Iteration:  78% 38/49 [00:13<00:04,  2.74it/s]\u001b[A\n",
            "Iteration:  80% 39/49 [00:14<00:03,  2.74it/s]\u001b[A\n",
            "Iteration:  82% 40/49 [00:14<00:03,  2.74it/s]\u001b[A\n",
            "Iteration:  84% 41/49 [00:14<00:02,  2.73it/s]\u001b[A\n",
            "Iteration:  86% 42/49 [00:15<00:02,  2.73it/s]\u001b[A\n",
            "Iteration:  88% 43/49 [00:15<00:02,  2.74it/s]\u001b[A\n",
            "Iteration:  90% 44/49 [00:16<00:01,  2.73it/s]\u001b[A\n",
            "Iteration:  92% 45/49 [00:16<00:01,  2.73it/s]\u001b[A\n",
            "Iteration:  94% 46/49 [00:16<00:01,  2.73it/s]\u001b[A\n",
            "Iteration:  96% 47/49 [00:17<00:00,  2.73it/s]\u001b[A\n",
            "Iteration:  98% 48/49 [00:17<00:00,  2.73it/s]\u001b[A\n",
            "Iteration: 100% 49/49 [00:17<00:00,  2.75it/s]\n",
            "Epoch: 100% 2/2 [00:35<00:00, 17.79s/it]\n",
            "06/06/2022 21:29:09 - INFO - __main__ -    global_step = 98, average loss = 2.773731526063413\n",
            "06/06/2022 21:29:09 - INFO - __main__ -   Saving model checkpoint to output\n",
            "06/06/2022 21:29:13 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n",
            "06/06/2022 21:29:14 - INFO - __main__ -   Creating features from dataset file at \n",
            "06/06/2022 21:29:14 - INFO - __main__ -   Saving features into cached file gpt2_cached_lm_1024_dev.txt\n",
            "06/06/2022 21:29:14 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "06/06/2022 21:29:14 - INFO - __main__ -     Num examples = 49\n",
            "06/06/2022 21:29:14 - INFO - __main__ -     Batch size = 4\n",
            "Evaluating: 100% 13/13 [00:05<00:00,  2.53it/s]\n",
            "06/06/2022 21:29:20 - INFO - __main__ -   ***** Eval results  *****\n",
            "06/06/2022 21:29:20 - INFO - __main__ -     perplexity = tensor(11.9726)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('output')\n",
        "model = GPT2LMHeadModel.from_pretrained('output').to(device)\n",
        "\n",
        "def generate(context, max_length=250):\n",
        "  input_ids = torch.tensor(tokenizer.encode(context)).unsqueeze(0).long().to(device)\n",
        "  sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=max_length, \n",
        "    top_k=0, \n",
        "    temperature=0.7\n",
        "  )\n",
        "  print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "SrexN0DsVT2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(\"Therefore, I think the question before the American people is:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D8vbbMgWAMj",
        "outputId": "ba75f5e6-cd7c-4b08-8fbd-17b85f1ed892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Therefore, I think the question before the American people is: Do we need a total ban on Muslims? Because I think it would be an enormous mistake to question the fundamental values of our nation and our nation today.\n",
            "\n",
            "I was in Afghanistan with my wife when the Taliban came. We were fighting for our country. I was there as a result of a ceasefire. If the Taliban came in and killed American soldiers, I would have been in a war. I think the best way to deal with them is with an objective, awake-eyed, focused military. I do. I think the best way for us to deal with them is with an objective, awake-eyed, focused military. And we can do so only if we're willing to defeat them. But if we don't, we will be in a war. And if we don't — and I think he does — we will be in a war. And that will involve a big part of the world. We will be fighting these terrorist networks. And we will be in the Middle East and Asia. I don't think that we ought to do that. And I think it is dangerous. But I think it is absolutely vital to keep our intelligence system up to date. It\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get embeddings ??"
      ],
      "metadata": {
        "id": "RtvFCAcg5XPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')  # or any other checkpoint\n",
        "word_embeddings = model.transformer.wte.weight  # Word Token Embeddings \n",
        "position_embeddings = model.transformer.wpe.weight  # Word Position Embeddings "
      ],
      "metadata": {
        "id": "MqIQycn-5Ksl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "text_index = tokenizer.encode('democrat',add_prefix_space=True)\n",
        "vector = model.transformer.wte.weight[text_index,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv97c9go5jM0",
        "outputId": "b1db3c1d-045c-4ea6-b132-e02674534e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3591e-01, -1.8655e-01,  1.3950e-01, -3.9529e-01,  4.2296e-02,\n",
            "          4.5229e-02, -4.4932e-01, -5.8396e-02,  2.5493e-02,  5.4011e-02,\n",
            "          8.9074e-02,  7.0771e-02,  6.7140e-02,  1.5853e-01,  1.2543e-01,\n",
            "         -8.5289e-02,  2.7138e-01, -9.5247e-02,  1.4170e-01,  1.3415e-01,\n",
            "         -2.3230e-01,  3.7137e-02, -9.8699e-02, -2.5814e-02,  1.0563e-01,\n",
            "          1.5063e-01, -4.6058e-02, -8.7054e-02,  4.5125e-02, -1.0115e-01,\n",
            "          1.1227e-01,  6.8431e-02,  1.2069e-01, -1.9956e-03,  2.6675e-01,\n",
            "         -1.2141e-03, -3.1552e-01, -3.4327e-02,  2.2123e-01,  2.8195e-03,\n",
            "         -2.3881e-01,  1.6937e-01,  4.0680e-02, -1.6229e-01, -1.4250e-01,\n",
            "          2.4010e-01,  9.6249e-02, -4.3696e-01, -9.4638e-02, -4.0206e-02,\n",
            "         -2.3277e-02, -2.0461e-01,  1.5137e-01,  1.2177e-01,  5.5813e-02,\n",
            "         -1.3548e-01,  2.2668e-01,  1.2863e-01, -9.3785e-02, -1.8028e-01,\n",
            "         -5.5448e-03,  2.0990e-01, -1.2376e-02,  7.5239e-02,  3.3157e-01,\n",
            "         -5.0512e-02, -1.7171e-01, -1.3174e-01,  1.6876e-01, -6.0552e-03,\n",
            "          1.9565e-01,  9.1668e-02, -2.0235e-01,  1.4964e-01,  1.2986e-01,\n",
            "         -7.0438e-02, -7.1135e-02,  2.3137e-01,  1.4280e-01, -9.4028e-02,\n",
            "         -1.2076e-02,  8.9007e-02,  7.0735e-02, -9.6015e-02,  2.0192e-01,\n",
            "          5.6293e-02, -1.3078e-01,  3.3586e-01,  6.2949e-02,  9.9780e-02,\n",
            "         -1.4136e-01,  1.7661e-02,  9.8949e-02,  2.6743e-01, -1.2520e-01,\n",
            "         -5.7332e-02,  1.6628e-01, -1.6500e-01,  9.9547e-02,  6.5486e-03,\n",
            "         -6.8094e-02,  6.5609e-02, -1.8448e-01, -9.7401e-02, -2.5723e-03,\n",
            "         -2.9185e-01, -2.4504e-02, -1.6752e-01, -8.0433e-02,  2.4914e-02,\n",
            "         -1.0550e-01,  5.9920e-02,  8.0966e-02,  2.4346e-01, -7.5308e-02,\n",
            "         -2.6993e-02,  1.8739e-01,  9.8728e-03, -3.6893e-02,  1.4244e-01,\n",
            "         -7.4368e-02, -2.8512e-01,  2.6040e-01,  1.9361e-01, -2.5468e-01,\n",
            "         -8.8633e-02,  2.8409e-01,  1.4927e-01,  7.0186e-02, -5.0838e-02,\n",
            "          2.3449e-01,  3.2264e-02,  2.4611e-01,  7.8181e-02,  5.7964e-02,\n",
            "         -1.9324e-01, -8.4408e-02, -3.7057e-02, -3.3597e-01, -4.7802e-02,\n",
            "          3.5033e-02, -1.0765e-01,  3.4749e-01, -1.1179e-02, -2.9145e-02,\n",
            "         -2.7727e-01, -1.3451e-01,  6.7344e-02, -2.2989e-01,  2.1354e-01,\n",
            "          1.6273e-01,  3.9708e-02, -2.0003e-02,  4.7778e-02, -1.8204e-01,\n",
            "          9.4623e-02, -2.2617e-01,  2.3142e-01, -6.2760e-02, -1.3402e-02,\n",
            "         -1.4842e-01,  9.2709e-02,  7.0998e-02, -1.8605e-01,  2.7809e-01,\n",
            "         -1.5141e-01,  2.0638e-02,  1.4821e-01,  4.6301e-02,  2.6254e-01,\n",
            "          2.4884e-01, -1.2171e-01,  8.6769e-02,  2.7392e-02,  6.7832e-02,\n",
            "          1.3425e-01,  5.8785e-02, -1.2635e-01,  7.0277e-02, -2.2626e-01,\n",
            "         -8.0627e-02,  7.1758e-03, -6.2263e-02,  2.8414e-02, -7.0773e-02,\n",
            "          2.3142e-02, -2.5325e-02,  1.0629e-01,  2.9744e-02, -2.2135e-01,\n",
            "         -9.5668e-02,  3.8357e-02, -1.4901e-01,  2.1162e-01,  5.3059e-02,\n",
            "          1.8213e-01, -1.2154e-01,  3.7511e-01, -1.2311e-02,  1.4419e-01,\n",
            "         -1.8530e-01,  1.6348e-01,  4.3411e-03,  2.1086e-01,  1.6247e-01,\n",
            "         -3.5086e-04,  1.3279e-01, -1.4635e-01, -2.7306e-02, -1.3243e-01,\n",
            "         -3.8154e-02, -1.6613e-01, -1.5594e-01, -1.7923e-01, -1.2562e-01,\n",
            "         -9.7184e-02, -1.1330e-01, -2.1309e-01,  1.1421e-01, -8.0288e-02,\n",
            "         -1.8309e-01, -1.4033e-01,  9.7115e-02,  5.2593e-03, -1.2156e-01,\n",
            "         -3.4628e-02,  7.7248e-02,  1.1857e-01,  1.6735e-01, -8.1019e-02,\n",
            "          4.1133e-02,  9.3258e-02, -3.3161e-01, -1.1409e-02, -2.9977e-01,\n",
            "         -5.2309e-02,  3.5034e-02, -2.6621e-01, -3.2196e-02, -2.5179e-01,\n",
            "         -8.6696e-02, -2.0917e-02, -2.6031e-02, -1.2213e-01,  1.4847e-02,\n",
            "          2.4510e-02,  2.0356e-01,  1.1593e-01,  1.8375e-01,  2.7815e-01,\n",
            "          7.2851e-02, -1.3882e-01,  2.0371e-01,  1.0390e-01,  2.4473e-02,\n",
            "         -2.6744e-01,  2.7515e-01, -1.8219e-01,  2.1177e-01, -2.4600e-02,\n",
            "         -2.8128e-01, -7.6691e-02,  2.1283e-01,  5.1517e-02, -2.4914e-01,\n",
            "         -3.1060e-02,  3.4280e-01, -2.4554e-01,  1.0305e-01, -2.0717e-01,\n",
            "          8.7452e-02, -2.0884e-01,  8.5322e-02, -2.9704e-01, -1.4591e-01,\n",
            "         -1.0669e-01,  5.3713e-04, -8.6480e-02,  5.6437e-02, -1.8479e-02,\n",
            "         -1.4105e-01, -4.7186e-02, -1.3724e-01,  9.4598e-02,  6.1121e-02,\n",
            "         -5.1696e-02, -1.6540e-02,  2.0019e-01, -2.5428e-01,  1.5630e-01,\n",
            "         -1.1554e-01,  1.7599e-01, -2.8784e-02, -1.4390e-01, -6.7202e-02,\n",
            "          7.2719e-03,  3.5482e-02,  2.9362e-01,  2.9632e-01,  3.6185e-02,\n",
            "         -3.2458e-02, -1.4473e-01, -1.5458e-01,  1.2857e-01, -4.4007e-02,\n",
            "          3.9762e-01, -1.7183e-01,  1.7125e-02,  6.8715e-02,  9.3071e-02,\n",
            "          1.6554e-01,  1.3242e-01,  2.3678e-02,  7.7418e-02,  1.7761e-01,\n",
            "          5.7136e-02, -2.3236e-01,  1.5249e-01, -9.0952e-02, -2.4313e-01,\n",
            "          1.3523e-01,  1.0449e-01, -4.2192e-02, -2.9224e-02, -1.7672e-01,\n",
            "          5.4212e-02, -3.2355e-01, -3.2180e-01,  9.6711e-02,  4.8529e-02,\n",
            "         -1.3349e-01, -1.9627e-01,  3.1846e-01,  8.5804e-02,  1.1598e-01,\n",
            "          1.1064e-01,  4.7988e-02,  1.3264e-01, -1.1419e-01,  3.7419e-02,\n",
            "          1.0047e-01, -2.2862e-01,  8.2100e-02,  1.1953e-01,  1.0057e-01,\n",
            "         -1.7906e-01, -8.0663e-02,  4.5001e-02,  8.2495e-02,  1.9966e-01,\n",
            "         -2.9209e-02, -9.4248e-02,  1.1796e-01,  1.3059e-01, -7.7212e-02,\n",
            "         -2.6800e-02,  1.3798e-01, -9.8515e-02, -6.0252e-02,  1.9146e-01,\n",
            "          2.0346e-01, -1.2949e-02, -2.1555e-01, -1.1660e-01, -1.3612e-01,\n",
            "          1.9800e-01, -1.2150e-01, -1.3702e-02, -9.2968e-02, -9.7377e-02,\n",
            "         -9.0871e-02, -2.8314e-02, -1.1518e-01,  3.0209e-01,  1.7975e-01,\n",
            "          4.4961e-02,  2.0878e-01, -2.7237e-02,  1.3263e-02, -6.4857e-02,\n",
            "         -1.1315e-02, -1.8761e-02, -8.7473e-02,  7.5245e-03,  8.9896e-03,\n",
            "          6.7991e-02,  4.1636e-02, -2.1391e-02, -1.9954e-01,  1.4180e-01,\n",
            "          4.4443e-02,  3.8410e-02,  7.8922e-02, -1.5810e-01,  2.1709e-01,\n",
            "          1.4944e-01,  1.8017e-01,  1.8197e-01,  2.2207e-01,  6.7588e-02,\n",
            "          3.0467e-02, -1.0554e-01, -1.2292e-01, -4.2929e-02, -2.0508e-01,\n",
            "          6.1553e-02, -3.2779e-01, -1.9181e-02, -1.5355e-01,  8.7237e-02,\n",
            "          2.3196e-01, -2.6068e-01,  5.6657e-02,  2.7139e-01,  8.2184e-02,\n",
            "         -1.3401e-01, -1.3465e-01, -6.6888e-02, -2.1808e-01, -2.3169e-01,\n",
            "          1.4145e-01,  1.0037e-01, -4.9997e-02,  1.8918e-02,  1.8544e-01,\n",
            "         -9.3360e-03,  4.1252e-02, -2.1104e-03, -3.5265e-01, -1.6541e-01,\n",
            "         -2.5668e-01, -6.3899e-02, -6.9040e-02,  1.4928e-01, -8.7952e-02,\n",
            "         -2.3380e-01,  7.7291e-02,  7.3155e-02,  1.4104e-01, -1.8306e-01,\n",
            "         -2.7387e-01, -1.1044e-01, -1.9923e-01, -1.3843e-01,  1.0480e-01,\n",
            "         -1.3542e-01,  3.4274e-01, -3.0963e-01,  3.4137e-03, -1.5024e-01,\n",
            "         -1.8227e-01,  3.8815e-02,  3.3861e-02,  8.4717e-02,  2.5360e-01,\n",
            "         -7.9315e-02,  1.7522e-01,  1.9404e-01, -4.9728e-02, -8.8987e-02,\n",
            "         -1.1295e-01, -4.5370e-02,  1.5896e-03, -6.2325e-02,  1.4282e-01,\n",
            "         -1.0632e-01, -3.4816e-01,  6.2985e-02, -9.6961e-03, -2.5589e-01,\n",
            "          1.1457e-01,  1.8148e-01,  2.0321e-01, -2.9822e-02, -6.5790e-02,\n",
            "          2.1225e-01, -2.5422e-01, -1.0667e-01,  1.0227e-01,  1.6845e-01,\n",
            "          3.3586e-01, -2.8489e-01,  4.5765e-02, -9.1194e-02,  1.0175e-01,\n",
            "          3.1154e-02,  9.7512e-02, -5.7848e-02, -1.1910e-01, -8.8019e-03,\n",
            "         -2.4154e-01, -9.9259e-02,  4.9326e-02, -2.8667e-01,  4.8683e-02,\n",
            "         -1.1047e-01, -2.0556e-01,  1.1203e-01, -3.4613e-01, -4.4349e-03,\n",
            "         -2.9638e-01,  6.0254e-02, -1.6357e-01,  2.7835e-01, -1.4865e-01,\n",
            "         -2.2190e-01,  3.4992e-02, -1.6087e-01,  1.3603e-01, -1.6288e-01,\n",
            "         -2.7719e-03,  4.8592e-02, -9.2809e-02, -7.0676e-02, -5.0401e-02,\n",
            "         -1.2171e-01, -1.4242e-01,  1.0619e-01,  1.4793e-01, -2.4037e-02,\n",
            "          2.5348e-01,  1.3787e-01, -1.1215e-01,  2.1774e-01, -8.3924e-02,\n",
            "          9.9094e-02,  3.5385e-01,  8.1505e-02,  9.8025e-03,  5.6607e-02,\n",
            "          1.3351e-02,  8.2098e-02,  1.5440e-01, -1.5690e-01, -8.6673e-02,\n",
            "          9.2102e-02,  1.2681e-01, -1.7954e-01, -1.6721e-03,  5.7974e-02,\n",
            "         -1.3315e-01,  5.9783e-02,  2.0860e-01,  3.2385e-01,  2.7930e-01,\n",
            "          6.4711e-02, -1.7536e-01,  5.5761e-02, -7.1718e-02,  1.5245e-01,\n",
            "         -1.3757e-02, -9.4465e-02,  4.2933e-02,  4.9973e-02,  1.6649e-01,\n",
            "         -1.3151e-01,  4.8100e-02, -1.5939e-03, -2.8826e-01,  9.9208e-03,\n",
            "          7.4793e-02,  3.8654e-02, -1.1122e-01,  4.2137e-02, -5.7565e-02,\n",
            "         -4.2707e-02, -2.1724e-01,  2.3217e-01,  5.7489e-02, -1.0617e-01,\n",
            "         -1.0179e-01,  1.1879e-01, -1.9322e-01,  2.3042e-01,  1.7494e-01,\n",
            "          1.5559e-01, -7.6896e-03,  9.4330e-02,  1.3853e-01,  4.1683e-01,\n",
            "         -1.4058e-01, -6.0458e-02, -8.6398e-02,  5.8888e-02, -1.1215e-01,\n",
            "         -1.2130e-01, -2.1793e-01,  6.4854e-02, -4.3754e-02, -1.0457e-03,\n",
            "         -2.0072e-01,  1.3631e-01,  1.8543e-01,  8.1478e-02, -5.0495e-02,\n",
            "          1.1633e-01,  5.2499e-02,  2.6121e-01,  8.5155e-02,  5.2795e-02,\n",
            "          1.5895e-01,  9.5373e-02,  9.0384e-02, -1.1763e-01, -1.0832e-01,\n",
            "         -2.0041e-01,  2.1575e-01, -8.0866e-02, -1.4578e-01,  2.4969e-02,\n",
            "          2.4096e-02, -1.2662e-01, -2.1582e-02, -2.6694e-02,  1.0174e-02,\n",
            "          6.4995e-02,  3.1274e-02, -1.0762e-01,  9.2613e-02, -3.4920e-03,\n",
            "         -2.4746e-01,  1.4321e-01, -1.2660e-02, -6.0908e-02,  1.2379e-01,\n",
            "         -3.7425e-02, -5.7371e-02,  1.4066e-01,  2.8199e-03,  5.7302e-02,\n",
            "         -8.1979e-02, -1.9458e-01,  6.8276e-02,  9.5098e-02, -8.4948e-03,\n",
            "          1.1978e-01,  4.0857e-02,  2.9887e-02,  1.4934e-01, -1.1387e-01,\n",
            "         -1.3673e-01, -4.5968e-02,  3.3548e-02,  2.2352e-01,  1.2504e-01,\n",
            "         -3.0093e-02,  2.7638e-02,  5.7825e-02, -2.5268e-01,  1.1627e-01,\n",
            "          4.2048e-02, -6.6170e-03, -2.1668e-01, -1.1933e-01, -4.9594e-02,\n",
            "         -1.1307e-01,  2.1975e-01,  1.1136e-01,  3.5267e-03, -2.2502e-01,\n",
            "          9.1276e-02, -5.9851e-02, -1.4195e-01, -2.0327e-01, -1.2693e-01,\n",
            "         -1.0417e-02, -1.1273e-01, -1.4073e-01, -2.7872e-01, -7.0103e-02,\n",
            "          1.5667e-01, -9.1702e-02,  3.4224e-02, -1.2120e-02,  8.6806e-02,\n",
            "         -1.6810e-01,  8.0417e-02, -1.8145e-01, -3.4529e-01, -8.6822e-02,\n",
            "          3.5563e-01,  1.1151e-01, -7.4189e-02,  5.8802e-02,  5.6790e-02,\n",
            "         -1.1413e-01,  1.2541e-01,  4.0784e-01, -9.0942e-02, -8.2421e-02,\n",
            "          8.6191e-02,  1.7862e-03, -1.0161e-01, -7.7595e-03, -1.5791e-01,\n",
            "          1.3094e-01, -2.1486e-01, -1.8886e-03, -1.4834e-01,  3.6943e-02,\n",
            "         -1.7845e-01,  6.0033e-03, -9.4288e-02,  2.2160e-01,  8.9598e-02,\n",
            "          1.4113e-01,  4.2456e-01,  2.6154e-01, -1.3371e-01,  3.8186e-01,\n",
            "         -5.0451e-02,  7.9185e-02,  5.3205e-02, -2.0200e-01,  6.9990e-02,\n",
            "          8.4678e-02,  4.0641e-03, -1.1278e-01, -7.3242e-02, -4.0656e-02,\n",
            "         -4.6605e-02,  2.3527e-01, -1.7210e-01,  8.8094e-02,  4.6014e-02,\n",
            "         -2.3863e-02, -7.7911e-02,  7.1087e-02,  8.0253e-02, -4.7969e-03,\n",
            "         -1.0175e-01,  1.2047e-01,  1.5582e-01, -1.1942e-01,  1.4123e-01,\n",
            "          7.7764e-02, -1.9746e-01,  2.0020e-01, -1.2863e-01,  1.2375e-01,\n",
            "         -1.8679e-02, -1.0143e-01, -2.3514e-01,  9.8727e-03,  1.0628e-01,\n",
            "          2.4346e-01,  4.3751e-02,  9.4090e-03, -2.1327e-02,  5.8627e-02,\n",
            "         -1.9179e-01,  5.2433e-01, -1.5485e-01,  8.4428e-02,  6.9631e-02,\n",
            "         -8.4154e-02,  7.5547e-02, -5.5148e-02,  1.5186e-01, -8.8054e-02,\n",
            "         -1.1374e-01, -1.4204e-01, -1.7732e-01,  1.9384e-01, -1.2649e-01,\n",
            "          1.7489e-01,  9.3754e-02,  5.2063e-02]], grad_fn=<IndexBackward0>)\n"
          ]
        }
      ]
    }
  ]
}